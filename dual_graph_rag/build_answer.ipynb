{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f1b83f0",
   "metadata": {},
   "source": [
    "# 1.Generation Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1624ffd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] wrote data/answer_gen.jsonl  n=5000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# ====== config ======\n",
    "IN_PATH = \"../outputs/dataset_sample_with_paths.jsonl\"\n",
    "OUT_PATH = \"../outputs/answer_gen.jsonl\"\n",
    "\n",
    "TOPK_ENTITY_PER_PAIR = 2\n",
    "TOPK_RES_PER_PAIR = 2\n",
    "MAX_PROMPT_CHARS = 6000\n",
    "\n",
    "SYSTEM = (\n",
    "    \"You are a DNS integrity anomaly detector. \"\n",
    "    \"Use the DNS record and evidence paths. Return ONLY valid JSON.\"\n",
    ")\n",
    "\n",
    "def clip(s, n):\n",
    "    return s if len(s) <= n else s[:n-3] + \"...\"\n",
    "\n",
    "def pick_topk_by_pair(paths, topk):\n",
    "    g = defaultdict(list)\n",
    "    for p in paths or []:\n",
    "        g[str(p.get(\"pair\", \"\"))].append(p)\n",
    "    keep = []\n",
    "    for pair, plist in g.items():\n",
    "        # sort low->high, keep topK highest scores, then restore low->high\n",
    "        plist = sorted(plist, key=lambda x: float(x.get(\"score\", 0.0)))\n",
    "        keep.extend(plist[-topk:] if topk > 0 else plist)\n",
    "    return sorted(keep, key=lambda x: float(x.get(\"score\", 0.0)))  # low->high (best near end)\n",
    "\n",
    "def build_assistant_answer(label_norm, evidence_paths):\n",
    "    \"\"\"\n",
    "    generate assistant answer JSON string\n",
    "    - label_norm: \"normal\" or \"anomalous\"\n",
    "    - evidence_paths: list of evidence path strings\n",
    "    \"\"\"\n",
    "    rationale = f\"The DNS record is classified as {label_norm}. \"\n",
    "    rationale += \"Based on the evidence paths retrieved, the anomaly or normality is determined as follows: \"\n",
    "    \n",
    "    rationale_details = []\n",
    "    for path in evidence_paths:\n",
    "        rationale_details.append(f\"- {path}\")\n",
    "    \n",
    "    rationale += \" \".join(rationale_details)\n",
    "    \n",
    "    obj = {\n",
    "        \"label\": label_norm,\n",
    "        \"confidence\": 0.75,  \n",
    "        \"rationale\": rationale, \n",
    "        \"evidence\": evidence_paths, \n",
    "    }\n",
    "    return json.dumps(obj, ensure_ascii=False)\n",
    "\n",
    "def build_prompt(sample):\n",
    "    record = sample[\"record\"]\n",
    "    paths = sample.get(\"paths\", {}) or {}\n",
    "\n",
    "    ent = pick_topk_by_pair(paths.get(\"entity\", []), TOPK_ENTITY_PER_PAIR)\n",
    "    res = pick_topk_by_pair(paths.get(\"resolution\", []), TOPK_RES_PER_PAIR)\n",
    "\n",
    "    parts = []\n",
    "    \n",
    "    parts.append(\"Task: Detect DNS integrity anomalies. Specifically, we focus on anomalies where the DNS resolution process is manipulated or hijacked. These anomalies may include situations where the DNS resolution returns incorrect or inaccessible responses due to malicious interventions such as cache poisoning, resolver manipulation, or unauthorized redirection.\")\n",
    "\n",
    "    parts.append(\"DNS Integrity Anomalies: These are DNS records where the resolution path has been altered without the domain owner's consent. Such anomalies can occur due to malicious activities like DNS hijacking, DNS manipulation, or network-level censorship. In this task, we aim to detect such anomalies by analyzing DNS records in the context of entity relationships and resolution behaviors.\")\n",
    "    \n",
    "    parts.append(\"The two paths used in this model are as follows:\")\n",
    "    parts.append(\"1) **Entity Graph Path**: This path represents the relationships between DNS entities such as domains, resolvers, countries, and policies. It captures the structural associations among the static attributes of DNS entities and is used to understand long-term relationships between entities that might indicate DNS manipulation.\")\n",
    "    parts.append(\"2) **Resolution Graph Path**: This path captures the historical resolution behavior of DNS records, which includes the domains' resolution patterns over time. It tracks how a domain's resolution has evolved, including any abnormal shifts that may indicate issues like DNS hijacking or manipulation.\")\n",
    "    \n",
    "    record_copy = record.copy()\n",
    "    if 'label' in record_copy:\n",
    "        del record_copy['label'] \n",
    "    parts.append(\"\\nDNS Record (raw JSON):\")\n",
    "    parts.append(json.dumps(record_copy, ensure_ascii=False)) \n",
    "    parts.append(\"\")\n",
    "    \n",
    "    parts.append(\"Evidence Paths (sorted by increasing score; strongest near the end):\")\n",
    "    idx = 1\n",
    "    parts.append(\"[EntityGraph]\")\n",
    "    if ent:\n",
    "        for p in ent:\n",
    "            parts.append(f\"[E{idx:02d}] score={float(p.get('score',0.0)):.6f} pair={p.get('pair','')}\")\n",
    "            parts.append(f\"  {p.get('path_str','')}\")\n",
    "            idx += 1\n",
    "    else:\n",
    "        parts.append(\"(none)\")\n",
    "\n",
    "    parts.append(\"[ResolutionGraph]\")\n",
    "    if res:\n",
    "        for p in res:\n",
    "            parts.append(f\"[E{idx:02d}] score={float(p.get('score',0.0)):.6f} pair={p.get('pair','')}\")\n",
    "            parts.append(f\"  {p.get('path_str','')}\")\n",
    "            idx += 1\n",
    "    else:\n",
    "        parts.append(\"(none)\")\n",
    "\n",
    "    parts.append(\"\")\n",
    "    parts.append(\n",
    "        \"Return ONLY this JSON:\\n\"\n",
    "        \"{\\n\"\n",
    "        '  \"label\": \"normal|anomalous\",\\n'\n",
    "        '  \"confidence\": 0.0-1.0,\\n'\n",
    "        '  \"rationale\": \"brief\",\\n'\n",
    "        '  \"evidence\": [\"E01\",\"E03\"]\\n'\n",
    "        \"}\"\n",
    "    )\n",
    "\n",
    "    return clip(\"\\n\".join(parts), MAX_PROMPT_CHARS)\n",
    "\n",
    "def main():\n",
    "    os.makedirs(os.path.dirname(OUT_PATH) or \".\", exist_ok=True)\n",
    "    n = 0\n",
    "    with open(IN_PATH, \"r\", encoding=\"utf-8\") as fin, open(OUT_PATH, \"w\", encoding=\"utf-8\") as fout:\n",
    "        for line in fin:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            s = json.loads(line)\n",
    "\n",
    "            # Extract the label from each record and generate a prompt\n",
    "            # Determine whether the label is anomaly or normal based on the dataset name\n",
    "            label_norm = \"normal\"  # normal\n",
    "\n",
    "            if s.get(\"record\", {}).get(\"label\") in [\"dataset1\", \"dataset2\", \"dataset3\", \"dataset4\"]:\n",
    "                label_norm = \"anomalous\"\n",
    "            \n",
    "            prompt = build_prompt(s)\n",
    "\n",
    "            # evidence paths\n",
    "            evidence_paths = []\n",
    "            for path in s.get(\"paths\", {}).get(\"entity\", []):\n",
    "                evidence_paths.append(f\"Entity Graph: {path.get('path_str', '')}\")\n",
    "            for path in s.get(\"paths\", {}).get(\"resolution\", []):\n",
    "                evidence_paths.append(f\"Resolution Graph: {path.get('path_str', '')}\")\n",
    "\n",
    "            # SFT\n",
    "            out = {\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": SYSTEM},\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                    {\"role\": \"assistant\", \"content\": build_assistant_answer(label_norm, evidence_paths)},  # 添加assistant答案\n",
    "                ],\n",
    "                \"metadata\": {\n",
    "                    \"qname\": s.get(\"record\", {}).get(\"name\", \"\"),\n",
    "                    \"timestamp\": s.get(\"record\", {}).get(\"timestamp\", \"\"),\n",
    "                    \"resolver\": (s.get(\"record\", {}).get(\"data\", {}) or {}).get(\"resolver\", \"\"),\n",
    "                    \"label\": label_norm  # 记录label，分离出label用于SFT\n",
    "                },\n",
    "            }\n",
    "            fout.write(json.dumps(out, ensure_ascii=False) + \"\\n\")\n",
    "            n += 1\n",
    "\n",
    "    print(f\"[OK] wrote {OUT_PATH}  n={n}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f214450e",
   "metadata": {},
   "source": [
    "# 2. FINE-TUNING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a6ab75",
   "metadata": {},
   "source": [
    "We use LLaMA-Factory to fine-tuning and test\n",
    "\n",
    "```\n",
    "git clone https://github.com/hiyouga/LLaMA-Factory.git\n",
    "cd LLaMA-Factory\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
